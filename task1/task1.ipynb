{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51766057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn libraries \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# libraries for smote and xgboost\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from xgboost import XGBClassifier\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset_task1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe7ac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Head ---\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "customerID           0\n",
      "gender               0\n",
      "SeniorCitizen        0\n",
      "Partner              0\n",
      "Dependents           0\n",
      "tenure               0\n",
      "PhoneService         0\n",
      "MultipleLines        0\n",
      "InternetService      0\n",
      "OnlineSecurity       0\n",
      "OnlineBackup         0\n",
      "DeviceProtection     0\n",
      "TechSupport          0\n",
      "StreamingTV          0\n",
      "StreamingMovies      0\n",
      "Contract             0\n",
      "PaperlessBilling     0\n",
      "PaymentMethod        0\n",
      "MonthlyCharges       0\n",
      "TotalCharges        11\n",
      "Churn                0\n",
      "dtype: int64\n",
      "UPDATED Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7032 non-null   float64\n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(17)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "--- Target Class Imbalance ---\n",
      "Churn\n",
      "No     0.73463\n",
      "Yes    0.26537\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Performing appropriate preprocessing and classification on the given dataset.  \n",
    "\n",
    "#basic eda od reading the data\n",
    "\n",
    "print(\"--- Data Head ---\")\n",
    "print(df.head())\n",
    "print(\"\\n--- Data Info ---\")\n",
    "print(df.info())\n",
    "\n",
    "#we drop the duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Convert totalcharges to numeric as some can be empty string vals, and we \"coerce\"/force the errors to NaN\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "#print the null values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#updated info after converting totalcharges to numeric\n",
    "print(\"UPDATED Data Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Target Class Imbalance ---\")\n",
    "print(df['Churn'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64035dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5634, 19)\n"
     ]
    }
   ],
   "source": [
    "# 2. Identify if the data is imbalanced and apply appropriate measures to handle it like SMOTE and feature extraction.  \n",
    "\n",
    "# Drop customerID as it's not a feature that would contribute to predict churn\n",
    "X = df.drop(['Churn', 'customerID'], axis=1)  \n",
    "\n",
    "# Convert 'Yes'/'No' to 1/0\n",
    "y = df['Churn'].map({'Yes': 1, 'No': 0})      \n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d752abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Perform Imputation based on Imputers available on Scikit Learn.Use bagging and boosting techniques. Perform LDA and QDA on the dataset.\n",
    "\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "                        'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "numerical_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "#Imputation is similar to fillna - its a subsitution technique for missing values and prevents data leakage\n",
    "num_imputer_mean = SimpleImputer(strategy='mean') # Use the mean for missing numbers\n",
    "num_imputer_median = SimpleImputer(strategy='median') # Use the median(meadians are less response to outliers so better when we have many outliers)\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent') # Use mode\n",
    "\n",
    "#defining the models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),  # bagging- tree-based multiple trees and voting technique\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'), # boosting tree based, next tree better than the previous\n",
    "    'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage=0.1), #straight line boundary to separate classes, assuming all classes share the same covariance\n",
    "    'QDA': QuadraticDiscriminantAnalysis() # curved decision boundary and  own unique covariance.\n",
    "}\n",
    "\n",
    "# number of trees \n",
    "param_grid = {'classifier__n_estimators': [50, 100]}\n",
    "\n",
    "\n",
    "# Now, we are using two methods, one is using mean and standard scaler, the other is using median and minmax scaler\n",
    "preprocessors = {\n",
    "    # Strategy 1: Using the average for missing numbers, and making sure the numeric data has a mean of 0 and std dev of 1.\n",
    "    'Mean_Standard': ColumnTransformer([\n",
    "        ('num', Pipeline([('imputer', num_imputer_mean), ('scaler', StandardScaler())]), numerical_features),\n",
    "        ('cat', Pipeline([('imputer', cat_imputer), ('encoder', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ], remainder='passthrough'),\n",
    "\n",
    "    # Strategy 2: Using the median for missing numbers (better against outliers), and scaling data between 0 and 1.\n",
    "    'Median_MinMax': ColumnTransformer([\n",
    "        ('num', Pipeline([('imputer', num_imputer_median), ('scaler', MinMaxScaler())]), numerical_features),\n",
    "        ('cat', Pipeline([('imputer', cat_imputer), ('encoder', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4f03bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shreya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Shreya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Training Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shreya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Shreya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Compare different approaches to scaling and imputing and analyze how they affect the model performance. Â \n",
    "# Evaluate the model using multiple metrics and justify which ones are most appropriate to use in the given scenario.\n",
    "\n",
    "results = {}\n",
    "for prep_name, prep in preprocessors.items():\n",
    "    # Looping through the models\n",
    "    for model_name, model in models.items():\n",
    "        \n",
    "        # Build the full pipeline: Preprocessor -> SMOTE -> Classifier\n",
    "        pipeline = ImbPipeline([\n",
    "            ('preprocessor', prep),\n",
    "            ('smote', SMOTE(random_state=42)), #smote to handle class imbalance\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Use GridSearchCV for hyperparameter tuning \n",
    "        # We use F1 score as the primary metric for tuning because the classes are imbalanced.\n",
    "        grid = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grid if model_name in ['RandomForest', 'XGBoost'] else {}, \n",
    "            cv=3, \n",
    "            scoring='f1', # Optimize for F1 score, which balances Precision and Recall\n",
    "            n_jobs=-1 \n",
    "        )\n",
    "        \n",
    "        # Train the model \n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred = grid.predict(X_test)\n",
    "\n",
    "        # Receiver Operating Characteristic - Area Under the Curve (ROC-AUC) is a performance metric for binary classification -Yes churn no Chrun\n",
    "        y_pred_proba = grid.predict_proba(X_test)[:, 1] if hasattr(grid.best_estimator_['classifier'], 'predict_proba') else None\n",
    "\n",
    "        # performance metrics \n",
    "        metrics = {\n",
    "            'Best Params': grid.best_params_ if model_name in ['RandomForest', 'XGBoost'] else {'classifier': 'Default'},\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1': f1_score(y_test, y_pred),\n",
    "            'ROC-AUC': roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 'N/A'\n",
    "        }\n",
    "        results[(prep_name, model_name)] = metrics\n",
    "\n",
    "print(\"\\n--- Model Training Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e55910e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Model Performance (Sorted by F1-Score) ---\n",
      "                                                  Best Params  Accuracy  \\\n",
      "Mean_Standard LDA                   {'classifier': 'Default'}  0.736693   \n",
      "Median_MinMax LDA                   {'classifier': 'Default'}  0.734564   \n",
      "              XGBoost        {'classifier__n_estimators': 50}  0.775727   \n",
      "Mean_Standard XGBoost        {'classifier__n_estimators': 50}  0.775727   \n",
      "Median_MinMax RandomForest   {'classifier__n_estimators': 50}  0.776437   \n",
      "Mean_Standard RandomForest  {'classifier__n_estimators': 100}   0.77005   \n",
      "              QDA                   {'classifier': 'Default'}  0.603974   \n",
      "Median_MinMax QDA                   {'classifier': 'Default'}  0.452803   \n",
      "\n",
      "                           Precision    Recall        F1   ROC-AUC  \n",
      "Mean_Standard LDA           0.502618  0.770053  0.608237  0.835676  \n",
      "Median_MinMax LDA                0.5  0.775401  0.607966   0.83309  \n",
      "              XGBoost       0.572139  0.614973  0.592784  0.824523  \n",
      "Mean_Standard XGBoost       0.573232  0.606952   0.58961  0.827956  \n",
      "Median_MinMax RandomForest  0.581717  0.561497  0.571429  0.814189  \n",
      "Mean_Standard RandomForest  0.567568  0.561497  0.564516  0.813527  \n",
      "              QDA           0.363095  0.652406  0.466539  0.649126  \n",
      "Median_MinMax QDA           0.303271  0.818182  0.442516  0.577167  \n"
     ]
    }
   ],
   "source": [
    "# 5. Final Results and Analysis\n",
    "\n",
    "# Converting to dataframe for ease of viewing\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n--- Combined Model Performance (Sorted by F1-Score) ---\")\n",
    "# Displaying the results, sorted by F1-Score to find the best balance of Precision and Recall.\n",
    "print(results_df.sort_values(by='F1', ascending=False))\n",
    "\n",
    "# Analysis:-\n",
    "# Recall is critical in this model because a False Negative -a customer predicted as No, but the customer infact does then churn, means losing a customer\n",
    "# Precision- A False Positive is unnecessary\n",
    "# F1-Score is the central optimization metric-balance between precision and recall\n",
    "# ROC-AUC is used to reliably compare models across all thresholds, as it is robust to the dataset's inherent class imbalance, confirming the overall discriminating power of the model.\n",
    "\n",
    "#mean_standard lda is the best model as it has highest f1 score and roc "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
